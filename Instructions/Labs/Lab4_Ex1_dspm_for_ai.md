---
lab:
  title: 演習 1 - AI 環境でデータを保護する
  module: Module 4 - Protect data in AI environments
---

## WWL テナント - 使用条件

講師が指導するトレーニング配信の一環としてテナントを提供されている場合は、講師が指導するトレーニングでハンズオンラボをサポートする目的でテナントを利用できることに注意してください。

テナントを共有したり、ハンズオンラボ以外の目的で使用したりしないでください。 このコースで使われるテナントは試用版テナントであり、クラスが終了し、拡張機能の対象となっていない場合は、使用したりアクセスしたりすることはできません。

テナントを有料サブスクリプションに変換することはできません。 このコースの一環として取得したテナントは Microsoft Corporation の財産のままであり、当社はいつでもアクセス権とリポジトリを取得する権利を留保します。

# ラボ 4 - 演習 1 - AI 環境でデータを保護する

あなたは、Contoso Ltd の情報セキュリティ管理者である Joni Sherman です。Microsoft Copilot などの AI ツールが毎日のワークフローに統合されるにつれて、チームは機密データに関する保護を評価して改善するように求められました。 このラボでは、Microsoft Purview の AI 用 DSPM を使用し、ポリシーの適用、リスク検出、露出評価を通じて AI ツールとのデータのやり取りをセキュリティで保護する方法について説明します。

**タスク**:

1. AI 用 DSPM を使用して生成 AI サイトの DLP ポリシーを作成する
1. リスクの高い AI の相互作用を検出するインサイダー リスク ポリシーを作成する
1. ラベルが設定されたコンテンツへの Copilot のアクセスをブロックする
1. データ評価を実行してラベル付けされていないコンテンツを検出する

## タスク 1 - AI 用 DSPM を使用して生成 AI サイトの DLP ポリシーを作成する

AI アシスタントによるデータ損失のリスクを軽減するには、まず、データ セキュリティの強化に関する推奨事項を使用して DLP ポリシーを作成します。 このポリシーでは、適応型保護を使用して、ChatGPT、Copilot in Edge、Chrome、Firefox などの AI ツールへの機密データの貼り付けまたはアップロードを制限します。

1. **SC-401-cl1\admin** アカウントで Client 1 VM (SC-401-CL1) に ログインします。

1. **Microsoft Edge** で、**`https://purview.microsoft.com`** に移動して **Joni Sherman**`JoniS@WWLxZZZZZZ.onmicrosoft.com` としてサインインします (ここで ZZZZZZ はラボ ホスティング プロバイダーから支給された一意のテナント ID です)。

1. Microsoft Purview で、**[ソリューション]**、**[AI 用 DSPM]**、**[推奨事項]** の順に選択して AI 用 DSPM に移動します。

1. **Fortify のデータ セキュリティ**推奨事項を選択します。

1. **[AI のデータ セキュリティ]** ポップアップ ページで概要を確認し、**[ポリシーを作成]** を選択します。 これにより、生成 AI サイトを対象とする事前構成済みの DLP ポリシーが作成されます。

1. ポリシーが作成されたら、**[ポリシーの表示]** を選択します。

1. **[ポリシーの詳細]** セクションで、**[ソリューションでポリシーを編集]** を選択し、Microsoft Purview で **[データ損失防止]** ソリューションを開きます。

1. **[ポリシー]** ページで、**AI 用 DSPM - AI サイトからの機密情報のブロック** ポリシーを見つけて選択します。

1. ポップアップで、**[シミュレーションの表示]** を選択します。

1. シミュレーション ダッシュボードで、**[ポリシーの編集]** を選択します。

1. **[ポリシーを適用する場所の選択]** ページが表示されるまで、**[次へ]** を選択します。 ポリシーのスコープが**デバイス**であることを確認します。

1. [**次へ**] を選択します。

1. **[詳細な DLP ルールのカスタマイズ]** ページで、**[リスクの高いユーザーに対してオーバーライドをブロックする]** の横にある鉛筆アイコンを選択してルールを表示します。

1. AI 用 DSPM で作成されたルールの構成を確認します。
   - **[条件]** で、含まれる機密情報の種類と、高いリスクに基づいて**適応型保護**がルールによって使用されることに注意してください。
   - **[アクション]** での [アップロード] アクティビティと [貼り付け] アクティビティの両方で、**[機密性の高いサービス ドメイン グループの制限]** の横にある **[編集]** を選択します。
   - サービス ドメイン グループの構成で、**[生成 AI Web サイト]** が **[オーバーライドによるブロック]** に設定されていることを確認します。

1. **[キャンセル]** を選択して、ルール エディターを変更せずに終了します。

1. **[詳細な DLP ルールのカスタマイズ]** ページに戻り、**[次へ]** を選択します。

1. **[ポリシー モード]** ページで、**[シミュレーションから 15 日間編集されていない場合はポリシーを適用する]** を選択し、**[次へ]** を選択します。

1. **[確認と終了]** ページで、**[送信]** を選択して、**[完了]** を選択します。

リスクの高いユーザーが生成 AI サイトで機密データを共有できないようにするポリシーを作成し、AI 用 DSPM で設定したポリシー構成を確認しました。

## タスク 2 - 危険な AI の相互作用を検出するインサイダー リスク ポリシーを作成する

次に、Copilot で危険なプロンプトの動作を検出するのに役立つポリシーを作成します。

1. Microsoft Purview で、**[ソリューション]**、**[AI 用 DSPM]**、**[推奨事項]** の順に選択して **[AI 用 DSPM]** に移動します。

1. **[AI アプリ (プレビュー) で危険な操作を検出する]** という推奨事項を選択します。

1. **[AI アプリでの危険な操作の検出 (プレビュー)]** ポップアップ ページで、概要を確認し、**[ポリシーを作成]** を選択します。

1. ポリシーが作成されたら、**[ポリシーの表示]** を選択します。

1. **[ポリシーの詳細]** セクションで、**[ソリューションでポリシーを編集]** を選択し、Microsoft Purview の **[インサイダー リスク管理]** エリアを開きます。

1. **[ポリシー]** ページで、**AI 用 DSPM - 危険な AI の使用を検出する**というポリシーを見つけて選択します。

1. ポップアップで、**[ポリシーの編集]** を選択して、ポリシー全体の構成を確認します。

1. **[ポリシー テンプレートの選択]** ページで、ポリシーが **"危険な AI の使用 (プレビュー)"** テンプレートを使用していることを確認します。

1. **[このポリシーのトリガー イベントの選択] ページ**に到達するまで **[次へ]** を選択します。
トリガー イベントが、危険な AI アクティビティの前後に発生する可能性のあるオフボード関連のリスクを通知する、**[Microsoft Entra ID から削除されたユーザー アカウント]** であることを確認します。

1. [**次へ**] を選択します。

1. **[インジケーター]** ページで、インジケーター カテゴリを展開して、選択されている次のようなシグナルを確認します。

   - 生成型 AI Web サイトを参照
   - Copilot から機密性の高い応答を受信
   - Copilot で危険なプロンプトを入力

1. **[確認と完了]** ページに到達するまで **[次へ]** を選択し、**[キャンセル]** を選択して、変更を加えずにエディターを終了します。

プロンプトや応答など、危険な AI 対話を検出するポリシーを作成して、危険なユーザー行動の初期の兆候を特定できるようになりました。

## タスク 3 - ラベルが設定されたコンテンツへの Copilot のアクセスをブロックする

Copilot が秘密度ラベルで保護されたコンテンツを使用して処理または応答できないようにすることで、リスクをさらに軽減できます。

1. Microsoft Purview で、**[ソリューション]**、**[AI 用 DSPM]**、**[推奨事項]** の順に選択して **[AI 用 DSPM]** に移動します。

1. **[Microsoft 365 Copilot とエージェントで参照されている機密データを保護する (プレビュー)]** という推奨事項を選択します。

1. この推奨事項に記載されているガイダンスを確認します。

1. **[ソリューション]**、**[データ損失防止]**、**[ポリシー]** の順に選択します。

1. **[+ ポリシーを作成]** を選択し、**[カスタム ポリシー]** を選択します。

1. **[DLP ポリシーの名前の設定]** ページで、以下を入力します。

   - **名前**: `DLP - Block Copilot access to labeled content`
   - **説明**: `Prevents Microsoft 365 Copilot from processing or responding with content labeled using sensitivity labels.`

1. **[ポリシーを適用する場所の選択]** ページが表示されるまで、**[次へ]** を選択します。

1. ポリシーのスコープとして **[Microsoft 365 Copilot (プレビュー)]** を選択し、**[詳細な DLP ルールのカスタマイズ]** ページが表示されるまで **[次へ]** を選択します。

1. **[ルールを作成]** を選択して、次を構成します。

   - **名前**: `Prevent Copilot from accessing labeled data`
   - **[条件]** で、**[条件の追加]**、**[コンテンツに含まれている]**、**[秘密度ラベル]** の順に選択します。 次の秘密度ラベルを追加します。
     - `Trusted People`
     - `Project - Falcon`
     - `Financial Data`
   - **[追加]** を選択します
   - **[アクション]** で、**[アクションの追加]**、**[Copilot がコンテンツを処理できないようする (プレビュー)]** の順に選択します。
   - **[ルールの作成]** ポップアップの下部にある **[保存]** を選択します。

1. **[詳細な DLP ルールのカスタマイズ]** ページに戻り、**[次へ]** を選択します。

1. **[ポリシー モード]** ページで、**[ポリシーをすぐに有効にする]** を選択し、**[次へ]** を選択します。

1. **[確認と完了]** ページで **[送信]** を選択し、**[新しいポリシーが作成されました]** ページで **[完了]** を選択します。

1. **[ソリューション]**、**[AI 用 DSPM]**、**[推奨事項]** の順に選択して、**[AI 用 DSPM]** に戻ります。

1. **[Microsoft 365 Copilot とエージェントで参照されている機密データを保護する (プレビュー)]** という推奨事項を選択し、**[完了としてマーク]** を選択します。

ラベルが設定されたコンテンツが Copilot のプロンプトと応答で使用されないようにする DLP ポリシーが作成されました。

## タスク 4: データ リスク評価を実行してラベルが設定されていないコンテンツを検出する

ラベル設定範囲の潜在的なギャップを把握するために、データ リスク評価を実行して、Copilot によってアクセスされる可能性のあるファイルで秘密度ラベルの無いものを特定します。

1. **[AI 用 DSPM]** で、**[Copilot 応答とエージェント応答で参照されている機密データを保護する]** という推奨事項を選択します。

1. **[Copilot 応答とエージェント応答で参照されている機密データを保護する]** ペインで概要を確認したあと、**[評価に移動]** を選択します。

1. **[データ リスク評価]** ページで、**[カスタム評価の作成 ]** を選択します。

1. **[基本情報]** ページで、次を入力します。

   - **名前**: `Unlabeled File Exposure Assessment`
   - **説明**: `Identifies files without sensitivity labels that may be exposed in Microsoft 365 Copilot responses and provides recommendations to reduce oversharing risks.`

1. [**次へ**] を選択します。

1. **[ユーザーの追加]** ページで、**[すべて]** を選択し、**[次へ]** を選択します。

1. **[評価するデータ ソースの追加]** ページで、既定の場所である **[SharePoint]** が選択されたままで **[次へ]** を選択します。

1. **[データ評価スキャンを確認して実行する]** ページで、**[保存して実行]** を選択します。

1. **[データ評価が正常に作成されました]** ページで、**[完了]** を選択します。

AI 用 Microsoft Purview DSPM を使用して、AI 関連のリスクを検出し、ポリシーを適用し、機密データの露出を評価できるようになって、組織が AI を安全に使用できるようになりました。
